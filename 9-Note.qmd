
# 補足のノート {-}

本章では，連関モデルの分析に必要なRの基本操作について補足する．クロス表の作成，`glm`と`gnm`の違い，RC連関モデルのスコアの正規化など，本文では詳しく扱えなかったトピックを解説する．

## パッケージ

本章で使用するパッケージを読み込む．

- `tidyverse`：データ操作・可視化のためのパッケージ群
- `broom`：モデル結果を整形するためのパッケージ（`tidy()`, `glance()`など）
- `gnm`：一般化非線形モデル（連関モデル）の推定
- `vcd`：カテゴリカルデータの可視化（モザイクプロットなど）

```{r}
#| message: false
library(tidyverse)
library(broom)
library(gnm)
library(vcd)
```


## クロス表の作成

「シリーズ編者による内容紹介」で使用したミッドタウン・マンハッタン研究のデータ（親の社会経済的地位SESと精神的健康MHS）を例に，クロス表の作成方法を示す．

```{r}
Freq <- c( 64,  94, 58, 46, 
           57,  94, 54, 40,
           57, 105, 65, 60,
           72, 141, 77, 94,
           36,  97, 54, 78,
           21,  71, 54, 71)
# byrow = TRUEとすることを忘れずに．
tab <- matrix(Freq, nrow = 6, ncol = 4, byrow = TRUE) |> as.table()
dimnames(tab)
dimnames(tab) <- list(SES = LETTERS[1:6],
                      MHS = c("well", "mild", "moderate", "impaired"))
tab
```



## 集計データの作成

`gnm`や`glm`で対数線形モデルを推定するには，クロス表ではなく**集計データ**（各セルの行・列インデックスと度数からなるデータフレーム）が必要である．ここでは集計データの作成方法を説明する．

- 表のデータではなく，各変数の組み合わせとその度数からなるデータを作成する．
- 度数はまず1行目について数値を並べ（1行1列から1行$I$列まで），次に2行目について数値を並べる（2行1列から2行$I$列まで）．これを`Freq`とする．
- 例として「編者による序文」の親の職業と精神的健康の例で考えてみる．これは$6\times4$のクロス表なので，まず1行1列から1行4列までの数字を入力し，次に2行1列から2行4列まで入力する．これを3行目から6行目まで繰り返す．表との対応を考えて適当な改行をいれるのもよい．ただしRは改行を入れても入れなくても，単に数値の列（ベクトル）として扱う．

- `gl`によって変数を作成する．度数がどの行と列に対応しているのかに注意してほしい．


```{r}
# 1行1列から1行4列，・・・・，6行1列から6行4列まで順に入力
Freq <- c( 64, 94, 58, 46, 57, 94, 54, 40, 57, 105, 65, 60, 72, 141, 77, 94, 36,  97, 54, 78, 21, 71, 54, 71)

# 表ようにして入力
Freq <- c( 64,  94, 58, 46, 
           57,  94, 54, 40,
           57, 105, 65, 60,
           72, 141, 77, 94,
           36,  97, 54, 78,
           21,  71, 54, 71)
```

- 行カテゴリと列カテゴリの数は$I$や$J$となっている．
- `I`を使いたいが，Rの関数にすでに用意されているので別の名前を考える．ここでは`NI`と`NJ`とする．
- 例のデータでは，行カテゴリ数$I = 6$，列カテゴリ数$J = 4$である．

```{r}
NI <- 6
NJ <- 4
```


- では，`Freq`に対応する行カテゴリと列カテゴリを並べてみる．先程の入力のルールにしたがうと，行については1行1列から1行4列までの数字を入力しているので`1,1,1,1`となり，次に`2,2,2,2`となる．これを繰り返し最後は`6,6,6,6`となる．列については，`1,2,3,4`が6回繰り返される．

```{r}
Row <- c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,6)
Col <- c(1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4,1,2,3,4)
class(Row)
class(Col)
```

- 属性が数値になっているので`as.factor`（または`factor`）で因子（factor）に変換する．

```{r}
Row <- as.factor(Row)
Col <- as.factor(Col)
class(Row);class(Col)
Row
Col
```

- 単純な数値の列を作成したければ`rep`関数が便利である．これは整数（integer）となる．

```{r}
Row <- rep(1:4, each = 5)
Col <- rep(1:5, length.out = 20)
class(Row)
class(Col)
Row <- as.factor(Row)
Col <- as.factor(Col)
class(Row)
class(Col)
Row
Col
```

- `gl`はGenerate Factor Levelsという関数で，`rep`に似ているが，数値ではなく因子を結果として出力する．
- 1から`n`までの数字をぞれぞれ`k`回繰り返して出力する．

```{r}
Row <- gl(n = 6, k = 4)
Col <- gl(n = 4, k = 1, length = 24)
class(Row)
class(Col)
Row
Col
```

- 以上より，`Freq`，`Row`，`Col`の3つの変数が作成された．これらからなるデータを作成する．`data.frame`と`tibble`のどちらでもよいが，
`tibble`の場合は表示させた後に，データの構造（`<dbl> <fct> <fct>`）が表示される．

```{r}
d <- data.frame(Freq, Row, Col)
d
# tibble でもよい
d <- tibble(Freq, Row, Col)
d
```

- 以上をまとめると次のようになる．本書のプログラム例では`gl`を使うことが多いのでここで使用方法を覚えておこう．

```{r}
Freq <- c( 64, 94, 58, 46, 57, 94, 54, 40, 57, 105, 65, 60, 72, 141, 77, 94, 36,  97, 54, 78, 21, 71, 54, 71)
NI <- 4
NJ <- 6
Row <- gl(n = NI, k = NJ, length = NI * NJ)
Col <- gl(n = NJ, k = 1, length = NI * NJ)
d <- tibble(Freq, Row, Col)
d
```




## GLMとGNMの結果の比較

対数線形モデルは`glm`でも推定できるが，RC連関モデルのような非線形パラメータを含むモデルには`gnm`が必要である．ここでは両者の出力の違いを確認する．

- `glm`と`gnm`では適合度や係数は同じだが，出力されるものが異なる．

```{r}
fit_glm <- glm(Freq ~ Row + Col, data = d, family = poisson)
fit_gnm <- gnm(Freq ~ Row + Col, data = d, family = poisson)
```


通常の出力も少し違う．

```{r}
fit_glm
fit_gnm
```


```{r}
names(fit_glm)
names(fit_gnm)
```

係数はもちろん同じ．

```{r}
summary(fit_glm)
summary(fit_gnm)
```

```{r}
tidy(fit_glm)
tidy(fit_gnm)
```

`null.deviance`と`df.null`が`gnm`では出力されない．
 
```{r}
glance(fit_glm)
glance(fit_gnm)
```


- gnmで独立モデルと飽和モデル

```{r}
fit_O <- gnm(Freq ~ Row + Col, data = d, family = poisson)
fit_S <- gnm(Freq ~ Row + Col + Row:Col, data = d, family = poisson)
```

- モデルの比較は`anova`で可能．

```{r}
anova(fit_O, fit_S)
```

```{r}
glance(fit_O)
glance(fit_S)
```


## 期待度数

- 期待度数を保存すれば期待度数についてのクロス表を作成することができる．飽和モデルの場合は，観測度数のクロス表と一致する．また独立モデルでの期待度数をみると，行によって列の幅が異なっていない（列によって行の幅がことなっていない）ことがわかる．

```{r}
d <- d |> mutate(O_Freq = fit_O$fitted.values,
              S_Freq = fit_S$fitted.values)
d |> xtabs(Freq ~ Row + Col, data = _) |> mosaic(shade = TRUE)
d |> xtabs(O_Freq ~ Row + Col, data = _) |> mosaic(shade = TRUE)
d |> xtabs(S_Freq ~ Row + Col, data = _) |> mosaic(shade = TRUE)
```

`fit_O$fitted.values`の代わりに`predict(fit_O, type = "response")`としても良い．`type = "response"`を忘れないようにする．


## モザイクプロット

- `gnm`パッケージには，`mentalHealth`が用意されているのでこれを使ってみる．

```{r}
mentalHealth
```

- `xtabs`は集計データからクロス表を作成する際に用いる．`xtabs(度数 ~ 行変数 + 列変数, data = データ名)`とすればよい．`mentalHealth`では`count`が度数を示している．

```{r}
tab_mentalHealth <- xtabs(count ~ SES + MHS, data = mentalHealth)
tab_mentalHealth
```

- `mosaic`でモザイクプロットを図示．影をつけたければ`shade = TRUE`とする．

```{r}
mosaic(tab_mentalHealth,
       shade = TRUE)
```

### 残差の種類

モザイクプロットの色付け（`shade = TRUE`）には残差が用いられる．残差にはいくつかの種類がある．

| 残差 | 定義 | 説明 |
|------|------|------|
| ピアソン残差 | $(f_{ij} - F_{ij}) / \sqrt{F_{ij}}$ | 期待度数の平方根で標準化 |
| 標準化残差 | $(f_{ij} - F_{ij}) / \sqrt{V_{ij}}$ | 分散$V_{ij}$で標準化 |

ここで$f_{ij}$は観測度数，$F_{ij}$は期待度数である．標準化残差の$V_{ij}$は次のように定義される．

$$
V_{ij} = F_{ij}(1 - p_{i+})(1 - p_{+j})
$$

$p_{i+}$は行$i$の周辺比率（$= n_{i+}/n$），$p_{+j}$は列$j$の周辺比率（$= n_{+j}/n$）である．標準化残差は漸近的に標準正規分布に従うため，$\pm 1.96$や$\pm 2.58$を基準に有意性を判断できる．


## 正規化

RC連関モデルでは，行スコア$\mu_i$と列スコア$\nu_j$，連関パラメータ$\phi$の間に識別の問題がある．例えば，$\mu_i$を2倍にして$\phi$を半分にしても同じモデルになる．この問題を解決するため，スコアに**正規化制約**を課す．

一般的な正規化制約は以下の通りである．

**単位正規化**（unit normalization）では重みなしの制約を課す．

- $\sum_i \mu_i = 0$，$\sum_j \nu_j = 0$
- $\sum_i \mu_i^2 = 1$，$\sum_j \nu_j^2 = 1$

**周辺重みづけ正規化**（marginal-weighted normalization）では周辺確率 $p_{i+} = n_{i+}/n_{++}$，$p_{+j} = n_{+j}/n_{++}$ を重みとして用いる．

- $\sum_i p_{i+}\mu_i = 0$，$\sum_j p_{+j}\nu_j = 0$
- $\sum_i p_{i+}\mu_i^2 = 1$，$\sum_j p_{+j}\nu_j^2 = 1$

周辺重みづけ正規化のもとで得られる$\phi$は**内的連関パラメータ**（intrinsic association parameter）と呼ばれ，正準相関係数$\rho$との間に $\phi = \rho/(1 - \rho^2)$ という一対一の関係がある（@goodman1981 ; 本章「連関モデルと正準相関分析」を参照）．$\phi$の範囲は$(-\infty, +\infty)$であり，$\phi = 0$が独立に対応する．単位正規化のもとでは$\phi$の値が異なり，正準相関との対応関係は成立しない．

`gnm`パッケージでは`getContrasts()`関数を使って正規化された推定値と標準誤差を得ることができる．

### ヘルパー関数の準備

- モデル適合度を表示するための関数を準備

```{r}
model.summary <- function(obj) {
  aic <- obj$deviance - obj$df * 2 # AIC(L2)
  bic <- obj$deviance - obj$df * log(sum(obj$y)) #BIC(L2)
  delta <-
    100 * sum(abs(obj$y - obj$fitted.values)) / (2 * sum(obj$y))
  p <- 1 - pchisq(obj$deviance, obj$df, lower.tail = F)
  Model <- deparse(substitute(obj))
  result <- tibble(
    "Model Description" = Model,
    "df" = obj$df,
    "L2" = obj$deviance,
    #"AIC(L2)" = aic,
    "BIC" = bic,
    "Delta" = delta,
    "p" = p
  )
  return(result)
}
```


- 変数と係数と係数の順番を表示するための関数を準備

```{r}
# 変数と係数と係数の順番を表示
var_num <- function(model) {
  data.frame(var = names(model$coefficients),
             estimate = model$coefficients) |>
    mutate(estimate = estimate,
           number = row_number())
}
```


- 通常のRCモデルでは行スコアと列スコアが正規化されていない．
- Agresti (2002) 

```{r}
set.seed(1)
##  Goodman Row-Column association model fits well (deviance 3.57, df 8)
mentalHealth$MHS <- C(mentalHealth$MHS, treatment)
mentalHealth$SES <- C(mentalHealth$SES, treatment)

# Independent Model
O <- gnm(count ~ SES + MHS,
         family = poisson, data = mentalHealth)

# Independent Modelの結果を利用して，初期値を設定
mult1 <- residSVD(O, SES, MHS)
RC1 <- gnm(
  count ~ SES + MHS + Mult(1, SES, MHS),
  start = c(coef(O), 1, mult1),
  family = poisson,
  data = mentalHealth
)
# Estimateには数字があるが，Std. ErrorがNAとなっている．これらのパラメータは識別されていない．
summary(RC1)
tidy(RC1)

# 行スコアと列スコアがどこにあるかを取り出す．
var_num(RC1)
# c(11:16,17:20)

# getContrastsによって正規化された推定値とその標準誤差を示す．まずは重み付けのない／単位標準化された解を求める．
mu_unit <- getContrasts(
  model = RC1,
  set = pickCoef(RC1, "[.]SES"),
  ref = "mean",
  scaleRef = "mean",
  scaleWeights = "unit"
)
nu_unit <- getContrasts(
  model = RC1,
  set = pickCoef(RC1, "[.]MHS"),
  ref = "mean",
  scaleRef = "mean",
  scaleWeights = "unit"
)
# 正規化された解を表示
mu_unit
nu_unit

# 正規化制約を確認
all.equal(sum(mu_unit$qvframe[, 1]), 0)
all.equal(sum(nu_unit$qvframe[, 1]), 0)
all.equal(sum(mu_unit$qvframe[, 1] ^ 2), 1)
all.equal(sum(nu_unit$qvframe[, 1] ^ 2), 1)

# 値の制約
con <- c(mu_unit$qvframe[, 1][c(1, 6)], nu_unit$qvframe[, 1][c(1, 4)])
con

RC1 <- gnm(
  count ~ SES + MHS + Mult(1, SES, MHS),
  constrain = c(11, 16, 17, 20),
  constrainTo = con,
  start = c(coef(O), NA, mult1),
  family = poisson,
  data = mentalHealth
)
summary(RC1)

## Marginal weighted solution
rowProbs <- with(mentalHealth, tapply(count, SES, sum) / sum(count))
colProbs <- with(mentalHealth, tapply(count, MHS, sum) / sum(count))
mu <- getContrasts(
  model = RC1,
  set = pickCoef(RC1, "[.]SES"),
  ref = rowProbs,
  scaleRef = rowProbs,
  scaleWeights = rowProbs
)
nu <- getContrasts(
  model = RC1,
  set = pickCoef(RC1, "[.]MHS"),
  ref = colProbs,
  scaleRef = colProbs,
  scaleWeights = colProbs
)
con <- c(mu$qvframe[, 1][c(1, 6)], nu$qvframe[, 1][c(1, 4)])
mu
nu
con

# 正規化制約を確認
all.equal(sum(mu$qvframe[, 1] * rowProbs), 0)
all.equal(sum(nu$qvframe[, 1] * colProbs), 0)
all.equal(sum(mu$qvframe[, 1] ^ 2 * rowProbs), 1)
all.equal(sum(nu$qvframe[, 1] ^ 2 * colProbs), 1)

RC1 <- gnm(
  count ~ SES + MHS + Mult(1, SES, MHS),
  constrain = c(11, 16, 17, 20),
  constrainTo = con,
  start = c(coef(O), NA, mult1),
  family = poisson,
  data = mentalHealth,
  tolerance = 1e-12
)
summary(RC1)
tidy(RC1)

# 周辺重みづけ正規化のもとでの内的連関パラメータ
phi <- summary(RC1)$coefficients["Mult(., SES, MHS).", 1]
rho <- (-1 + sqrt(1 + 4 * phi ^ 2)) / (2 * phi)
eta <- (2 * phi) ^ (-1)
tau <- (1 + eta ^ 2) ^ (1 / 2) - eta
list(phi = phi, rho = rho, eta = eta, tau = tau)
all.equal(rho, tau)
```



## 初期値

RC連関モデルは非線形モデルであるため，最尤推定が局所解に収束したり，収束に失敗したりすることがある．良い初期値を与えることで，これらの問題を回避できる．

`gnm`パッケージの`residSVD()`関数は，独立モデルの残差に対して特異値分解（SVD）を行い，RC連関モデルの初期値を生成する．この方法は @goodman1979a の対応分析との関連に基づいている．

```{r}
# データの準備
Freq <- c( 39, 50, 18,  4,
          140,178, 85, 23,
          108,195, 97, 23,
          238,598,363,111,
           78,250,150, 55,
           50,200,208, 74,
            8, 29, 46, 21)


tab_2.3A <-
  matrix(Freq,
         nrow = 7,
         ncol = 4,
         byrow = TRUE) |> as.table()

polviews <- gl(n = 7, k = 4)
fefam <- gl(n = 4, k = 1, length = 28)
freq_tab_2.3A <- tibble(Freq, polviews, fefam)
freq_tab_2.3A

# 独立モデル
O <- freq_tab_2.3A |> gnm(
  Freq ~ polviews + fefam,
  family = poisson,
  data = _,
  tolerance = 1e-12
)

var_num(O)

RC <- freq_tab_2.3A |>
  gnm(
    Freq ~ polviews + fefam +
      Mult(1, polviews, fefam),
    family = poisson,
    data = _,
    tolerance = 1e-12
  )
var_num(RC)

mult1 <- residSVD(O, polviews, fefam)
mult2 <- residSVD(O, polviews, fefam, d = 2)
mult3 <- residSVD(O, polviews, fefam, d = 3)

RC <- freq_tab_2.3A |>
  gnm(
    Freq ~ polviews + fefam + Mult(1, polviews, fefam),
    start = c(coef(O), NA, mult1),
    family = poisson,
    data = _,
    tolerance = 1e-12
  )
summary(RC)
tidy(RC)
glance(RC)

RC2 <- freq_tab_2.3A |>
  gnm(
    Freq ~ polviews + fefam +
      Mult(1, polviews, fefam, inst = 1) +
      Mult(1, polviews, fefam, inst = 2),
    start = c(coef(O), NA, mult2[, 1], NA, mult2[, 2]),
    family = poisson,
    data = _,
    tolerance = 1e-12
  )
summary(RC2)
tidy(RC2)
glance(RC2)

RC3 <- freq_tab_2.3A |>
  gnm(
    Freq ~ polviews + fefam + Mult(1, polviews, fefam, inst = 1) +
      Mult(1, polviews, fefam, inst = 2) +
      Mult(1, polviews, fefam, inst = 3),
    start = c(coef(O), NA, mult3[, 1], NA, mult3[, 2], NA, mult3[, 3]),
    family = poisson,
    data = _,
    tolerance = 1e-12
  )
summary(RC3)
tidy(RC3)
glance(RC3)

library(logmult)
anoas_model <- anoas(tab_2.3A, nd = 3)
anoas_model

rc(tab_2.3A, nd = 1)
rc(tab_2.3A, nd = 2)
rc(tab_2.3A, nd = 3)

bind_rows(model.summary(O),
          model.summary(RC),
          model.summary(RC2),
          model.summary(RC3))
```

### 別のデータでの検証

教科書の表2.3Bのデータ（教育と職業の連関）についても同様の分析を行う．



```{r}
## 表2.3B
Freq <- c(518,  95, 6, 35, 5,
         　 81,  67, 4, 49, 2,
          452,1003,67,630, 5,
           71, 157,37,562,12)


# データを表形式に変換
tab_2.3B <-
  matrix(Freq,
         nrow = 4,
         ncol = 5,
         byrow = TRUE) |> as.table()

tab_2.3B
# 度数，行変数，列変数からなる集計データを作成
Educ <- gl(n = 4, k = 5)
Occ <- gl(n = 5, k = 1, length = 20)
freq_tab_2.3B <- tibble(Freq, Educ, Occ)
freq_tab_2.3B


O <- freq_tab_2.3B |> 
  gnm(Freq ~ Educ + Occ,
         family = poisson,
         data = _,
         tolerance = 1e-12)

mult1 <- residSVD(O, Educ, Occ)
mult2 <- residSVD(O, Educ, Occ, d = 2)
mult3 <- residSVD(O, Educ, Occ, d = 3)

RC <- freq_tab_2.3B |>
  gnm(
    Freq ~ Educ + Occ + Mult(1, Educ, Occ),
    family = poisson,
    data = _,
    tolerance = 1e-12
  )

var_num(RC)

RC <- freq_tab_2.3B |>
  gnm(
    Freq ~ Educ + Occ + Mult(1, Educ, Occ),
    start = c(coef(O), 10, mult1),
    family = poisson,
    data = _,
    tolerance = 1e-12
  )

RC2 <- freq_tab_2.3B |>
  gnm(
    Freq ~ Educ + Occ + instances(Mult(1, Educ, Occ), 2),
    #      start = c(coef(O), NA, mult2[,1], NA, mult2[,2]),
    family = poisson,
    data = _,
    tolerance = 1e-12
  )
RC2


RC3 <- freq_tab_2.3B |>
  gnm(
    Freq ~ Educ + Occ + instances(Mult(1, Educ, Occ), 3),
    start = c(coef(O), NA, mult3[, 1], NA, mult3[, 2], NA, mult3[, 3]),
    family = poisson,
    data = _,
    tolerance = 1e-12
  )
RC3

bind_rows(model.summary(O),
          model.summary(RC),
          model.summary(RC2),
          model.summary(RC3))

anoas_model <- anoas(tab_2.3B, nd = 3)
anoas_model
```





## 位相モデル

**位相モデル（topological model）**は，クロス表の特定のセル（通常は対角セル）に特別なパラメータを割り当てるモデルである．社会移動表の分析では，対角セルは「非移動（immobility）」を表し，特別な扱いが必要な場合がある．

代表的な位相モデルとして以下がある．

- **準独立モデル（QI: Quasi-Independence）**：対角セルを飽和させ，非対角セルに独立モデルを適用
- **一様連関＋対角（U+Diag）**：一様連関モデルに対角効果を追加

ここでは`occupationalStatus`データ（英国の世代間職業移動表）を用いて位相モデルを推定する．

```{r}
occupationalStatus
freq_occupationalStatus <- data.frame(occupationalStatus)
freq_occupationalStatus <- freq_occupationalStatus |> 
  mutate(
    diag = ifelse(origin == destination, origin, 0) |> factor(),
    Rscore = scale(as.numeric(origin), scale = FALSE),
    Cscore = scale(as.numeric(destination), scale = FALSE)
  )

fit_O <-
  gnm(Freq ~ origin + destination, family = poisson, data = freq_occupationalStatus)
fit_QI <-
  gnm(Freq ~ origin + destination + diag,
      family = poisson,
      data = freq_occupationalStatus)
fit_U <-
  gnm(Freq ~ origin + destination + Rscore:Cscore,
      family = poisson,
      data = freq_occupationalStatus)
fit_QI_U <-
  gnm(Freq ~ origin + destination + diag + Rscore:Cscore,
      family = poisson,
      data = freq_occupationalStatus)
fit_S <-
  gnm(Freq ~ origin + destination + origin:destination,
      family = poisson,
      data = freq_occupationalStatus)

freq_occupationalStatus <- freq_occupationalStatus |> 
  mutate(
    diag1 = ifelse(origin == 1 &
                     origin == destination, 1, 0) |> factor(),
    diag2 = ifelse(origin == 2 &
                     origin == destination, 1, 0) |> factor(),
    diag3 = ifelse(origin == 3 &
                     origin == destination, 1, 0) |> factor(),
    diag4 = ifelse(origin == 4 &
                     origin == destination, 1, 0) |> factor(),
    diag5 = ifelse(origin == 5 &
                     origin == destination, 1, 0) |> factor(),
    diag6 = ifelse(origin == 6 &
                     origin == destination, 1, 0) |> factor(),
    diag7 = ifelse(origin == 7 &
                     origin == destination, 1, 0) |> factor(),
    diag8 = ifelse(origin == 8 &
                     origin == destination, 1, 0) |> factor()
  )

fit_QI2 <-
  gnm(
    Freq ~ origin + destination + diag1 + diag2 + diag3 + diag4 + diag5 + diag6 + diag7 + diag8,
    family = poisson,
    data = freq_occupationalStatus
  )

summary(fit_QI)
summary(fit_QI2)

anova(fit_O, fit_QI, fit_U, fit_QI_U, fit_S)

bind_rows(
  model.summary(fit_O),
  model.summary(fit_QI),
  model.summary(fit_U),
  model.summary(fit_QI_U),
  model.summary(fit_S)
)

```


```{r}
data(erikson)
erikson
dimnames(erikson)
dimnames(erikson)$origin <-
  c("I+II","I+II","III","IVab","IVab","IVc","V/VI","VIIa","VIIb")
dimnames(erikson)$destination <-
  c("I+II","I+II","III","IVab","IVab","IVc","V/VI","VIIa","VIIb")
freq_erikson <- data.frame(erikson)
erikson2 <-
  xtabs(Freq ~ origin + destination + country, data = freq_erikson)
freq_erikson <- data.frame(erikson2)

levelMatrix <- rep(c(2, 3, 4, 6, 5, 6, 6,
                     3, 3, 4, 6, 4, 5, 6,
                     4, 4, 2, 5, 5, 5, 5,
                     6, 6, 5, 1, 6, 5, 2,
                     4, 4, 5, 6, 3, 4, 5,
                     5, 4, 5, 5, 3, 3, 5,
                     6, 6, 5, 3, 5, 4, 1), times = 3) |> as.factor()
d <- bind_cols(freq_erikson, levelMatrix = levelMatrix)

fit_O <-
  gnm(
    Freq ~ origin + destination + country + origin * country +
      destination * country,
    family = poisson,
    data = d
  )


fit_Common <- gnm(
  Freq ~ origin + destination + country +
    origin * country + destination * country +
    origin * destination,
  family = poisson,
  data = d
)

fit_Common_Pattern <- gnm(
  Freq ~ origin + destination + country +
    origin * country + destination * country + levelMatrix,
  family = poisson,
  data = d
)

d <- d |> 
  mutate(
  pred1 = fit_O$fitted.values,
  pred2 = fit_Common$fitted.values,
  pred3 = fit_Common_Pattern$fitted.values
)

summary(fit_O)
names(fit_Common)
names(summary(fit_Common))
summary(fit_Common)
anova(fit_O, fit_Common_Pattern, fit_Common)
```


## 連関モデルと正準相関分析

RC連関モデルと正準相関分析には密接な関係がある．@goodman1981 は，周辺重みづけ正規化（$\sum_i p_{i+}\mu_i = 0$，$\sum_i p_{i+}\mu_i^2 = 1$，$\sum_j p_{+j}\nu_j = 0$，$\sum_j p_{+j}\nu_j^2 = 1$）のもとで得られる内的連関パラメータ$\phi$から，正準相関係数$\rho$を導出できることを示した．

$$
\rho = \frac{-1 + \sqrt{1 + 4\phi^2}}{2\phi}
$$

逆に$\rho$から$\phi$を求めると$\phi = \rho/(1 - \rho^2)$である．$\phi$は$(-\infty, +\infty)$の範囲をとり，$\phi = 0$が独立に対応する．$\rho$は通常の相関係数と同じ$(-1, 1)$の範囲をとる．この関係により，連関モデルはクロス表に対する正準相関分析の確率モデル版と見なすことができる．以下では @goodman1981 のTable 1のデータを用いて，様々な連関モデルを比較する．

```{r}
library(tidyverse)
library(gnm)
Freq <- c(5, 3, 10, 11, 4, 5, 8, 6, 26, 11, 3, 6, 23, 11, 1, 2)
Row <- gl(n = 4, k = 4)
Col <- gl(n = 4, k = 1, length = 16)
d <- tibble(Freq, Row, Col) |> 
    mutate(U = as.numeric(Row),
         V = as.numeric(Col))
xtabs(Freq ~ Row + Col, data = d)
```


```{r}
# (1) O
O <- d |> 
  gnm(Freq ~ Row + Col,
      family = poisson,
      data = _)
# (2) U
U <- d |> 
  gnm(Freq ~ Row + Col + U:V,
      family = poisson,
      data = _)
# (3) R
R <- d |> 
  gnm(Freq ~ Row + Col + Row:V,
      family = poisson,
      data = _)
# (4) C
C <- d |> 
  gnm(Freq ~ Row + Col + Col:U,
      family = poisson,
      data = _)
# (5) RC
RC <- d |> 
  gnm(Freq ~ Row + Col + Mult(1, Row, Col),
      family = poisson,
      data = _)
# (6) U + RC
UplusRC <- d |> 
    gnm(Freq ~ Row + Col + U:V + Mult(1, Row, Col),
      family = poisson,
      data = _)
# (7) R + RC
RplusRC <- d |> 
    gnm(Freq ~ Row + Col + Row:V + Mult(1, Row, Col),
      family = poisson,
      data = _)
# (8) C + RC
CplusRC <- d |> 
    gnm(Freq ~ Row + Col + Col:U + Mult(1, Row, Col),
      family = poisson,
      data = _)
# (9) R + C + RC
RplusCplusRC <- d |> 
    gnm(Freq ~ Row + Col + Row:V + Col:U + Mult(1, Row, Col),
      family = poisson,
      data = _)
# (10) R + C
RplusC <- d |> 
    gnm(Freq ~ Row + Col + Row:V + Col:U,
      family = poisson,
      data = _)

list(O, U, R, C, RC, UplusRC, RplusRC, CplusRC, RplusCplusRC, RplusC) |> 
  map_dfr(glance, id = "Model")
```




```{r}
fit <-
  gnm(Freq ~ Row + Col + Mult(1, Row, Col),
      family = poisson,
      data = d)
summary(fit)

rowProbs <- with(d, tapply(Freq, Row, sum) / sum(Freq))
colProbs <- with(d, tapply(Freq, Col, sum) / sum(Freq))
mu <- getContrasts(
  fit,
  pickCoef(fit, "[.]Row"),
  ref = rowProbs,
  scaleRef = rowProbs,
  scaleWeights = rowProbs
)
nu <- getContrasts(
  fit,
  pickCoef(fit, "[.]Col"),
  ref = colProbs,
  scaleRef = colProbs,
  scaleWeights = colProbs
)
fit <-
  gnm(
    Freq ~ Row + Col + Mult(1, Row, Col),
    family = poisson,
    data = d,
    constrain = 9:16,
    constrainTo = c(mu$qvframe[, 1], -1 * nu$qvframe[, 1])
  )

mu_score <- rep(mu$qvframe[, 1], each = 4)
nu_score <- rep(nu$qvframe[, 1], 4)
d <- d |>  mutate(mu = mu_score,
              nu = nu_score)

# Canonical correlation
library(wCorr)
with(d, weightedCorr(mu, x = nu, weights = Freq, method = "Pearson"))
with(d, weightedCorr(U, x = V, weights = Freq, method = "Polychoric"))

library(polycor)

library(vcdExtra)
d_ind <- expand.dft(d, dreq = "Freq")
d_ind
library(DescTools)
CorPolychor(d_ind$U, d_ind$V, ML = TRUE)


# 
summary(fit)
phi <- fit$coefficients["Mult(., Row, Col)."] |> abs()
rho <- (-1 + sqrt(1 + 4 * phi ^ 2)) / (2 * phi)
eta <- (2 * phi) ^ (-1)
tau <- (1 + eta ^ 2) ^ (1 / 2) - eta
mu
nu
phi
rho
tau
delta_mu <- abs((-1.3354658 - 1.1376491) / (1 - 4))
delta_nu <- abs((-0.8513968 - 1.0822644) / (1 - 4))
# Adjusted
tau * ((1 - delta_mu / 12) * (1 - delta_nu / 12)) ^ (-1 / 2)

library(logmult)
tab <- matrix(Freq,
              nrow = 4,
              ncol = 4,
              byrow = TRUE)
rc2 <- rc(tab,
          nd = 1,
          weighting = "marginal",
          se = "bootstrap")
summary(rc2)
assoc(rc2)
```

